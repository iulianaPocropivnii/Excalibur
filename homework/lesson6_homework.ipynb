{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have the latest version of sigmoid_check installed by running pip install sigmoid_check --upgrade\n",
    "from sigmoid_check.excalibur import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Extract DataFrame `df_social_media_metrics` subset for rows where 'Likes' exceed 'Shares' and store it in `highly_liked_posts`.\n",
    "@check_pandas_101\n",
    "def pandas_101(df_social_media_metrics):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    highly_liked_posts = df_social_media_metrics[\n",
    "        df_social_media_metrics[\"Likes\"] > df_social_media_metrics[\"Shares\"]\n",
    "    ]\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"highly_liked_posts\": highly_liked_posts}\n",
    "\n",
    "\n",
    "pandas_101()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_product_info` to group by 'Category', computing the minimum 'Price' for each category, storing result as `min_price_by_category`.\n",
    "@check_pandas_102\n",
    "def pandas_102(df_product_info):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    min_price_by_category = df_product_info.groupby(\"Category\")[\"Price\"].min()\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"min_price_by_category\": min_price_by_category}\n",
    "\n",
    "\n",
    "pandas_102()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Apply datetime filtering on `df_online_sessions` to store sessions in the month of January 2023 in variable `january_sessions` based on 'SessionStart'.\n",
    "@check_pandas_103\n",
    "def pandas_103(df_online_sessions):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    df_online_sessions[\"SessionStart\"] = pd.to_datetime(\n",
    "        df_online_sessions[\"SessionStart\"]\n",
    "    )\n",
    "    january_sessions = df_online_sessions[\n",
    "        (df_online_sessions[\"SessionStart\"].dt.month == 1)\n",
    "        & (df_online_sessions[\"SessionStart\"].dt.year == 2023)\n",
    "    ]\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"january_sessions\": january_sessions}\n",
    "\n",
    "\n",
    "pandas_103()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_employee_entries` and fill NA in 'EntryTime' with '08:00 AM', storing the result in `filled_employee_entries`.\n",
    "@check_pandas_104\n",
    "def pandas_104(df_employee_entries):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    filled_employee_entries = df_employee_entries.fillna({\"EntryTime\": \"08:00 AM\"})\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"filled_employee_entries\": filled_employee_entries}\n",
    "\n",
    "\n",
    "pandas_104()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Drop all columns with any NA values in DataFrame `df_transaction_records`, storing cleaned version as `non_na_transactions`.\n",
    "@check_pandas_105\n",
    "def pandas_105(df_transaction_records):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    non_na_transactions = df_transaction_records.dropna(axis=1)\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"non_na_transactions\": non_na_transactions}\n",
    "\n",
    "\n",
    "pandas_105()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a Series `series_ascending` from a list of numbers [1, 2, 3, 4, 5], using these values as the indices as well.\n",
    "@check_pandas_106\n",
    "def pandas_106():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    series_ascending = pd.Series([1, 2, 3, 4, 5], index=[1, 2, 3, 4, 5])\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"series_ascending\": series_ascending}\n",
    "\n",
    "\n",
    "pandas_106()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Use the query method on DataFrame `df_financial_audit` to extract entries with 'Audit' == 'Complete' and 'Amount' > 10000, saving it as `completed_audits`.\n",
    "@check_pandas_107\n",
    "def pandas_107(df_financial_audit):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"completed_audits\": completed_audits}\n",
    "\n",
    "\n",
    "pandas_107()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create a custom `percent_round` function and apply it to round the 'Progress' column in DataFrame `df_student_projects` to the nearest ten, storing result as `rounded_progress`.\n",
    "@check_pandas_108\n",
    "def pandas_108(df_student_projects):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"rounded_progress\": rounded_progress}\n",
    "\n",
    "\n",
    "pandas_108()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Extract the elements starting from the 10th index to the 20th index from `df_user_activity`, storing the result in `sampled_user_activity`.\n",
    "@check_pandas_109\n",
    "def pandas_109(df_user_activity):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"sampled_user_activity\": sampled_user_activity}\n",
    "\n",
    "\n",
    "pandas_109()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use advanced indexing to set all negative values in DataFrame `df_temperature_fluctuations` to zero, storing corrected DataFrame as `non_negative_temperatures`.\n",
    "@check_pandas_110\n",
    "def pandas_110(df_temperature_fluctuations):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    non_negative_temperatures = df_temperature_fluctuations.where(\n",
    "        df_temperature_fluctuations >= 0, 0\n",
    "    )\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"non_negative_temperatures\": non_negative_temperatures}\n",
    "\n",
    "\n",
    "pandas_110()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# With DataFrame `df_fleet_inventory`, allocate memory efficiency by converting 'Year' column to category, saving the result as `efficient_fleet_inventory`.\n",
    "@check_pandas_111\n",
    "def pandas_111(df_fleet_inventory):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    df_fleet_inventory[\"Year\"] = df_fleet_inventory[\"Year\"].astype(\"category\")\n",
    "    efficient_fleet_inventory = df_fleet_inventory\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"efficient_fleet_inventory\": efficient_fleet_inventory}\n",
    "\n",
    "\n",
    "pandas_111()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_respiratory_data` to calculate cumulative maximum of 'Pulse' within groups of 'PatientID', storing it as `grouped_cumulative_max`.\n",
    "@check_pandas_112\n",
    "def pandas_112(df_respiratory_data):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    grouped_cumulative_max = df_respiratory_data.groupby(\"PatientID\")[\"Pulse\"].cummax()\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"grouped_cumulative_max\": grouped_cumulative_max}\n",
    "\n",
    "\n",
    "pandas_112()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Group DataFrame `df_weather_statistics` and apply aggregation to find both 'mean' and 'std' of 'Temperature', storing multi-aggregate result as `weather_stats`.\n",
    "@check_pandas_113\n",
    "def pandas_113(df_weather_statistics):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"weather_stats\": weather_stats}\n",
    "\n",
    "\n",
    "pandas_113()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a hierarchical index on DataFrame `df_multilayer_data` using [('Region', 'State')], saving the result as `hierarchical_multilayer`.\n",
    "@check_pandas_114\n",
    "def pandas_114(df_multilayer_data):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    hierarchical_multilayer = df_multilayer_data.set_index([\"Region\", \"State\"])\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"hierarchical_multilayer\": hierarchical_multilayer}\n",
    "\n",
    "\n",
    "pandas_114()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the exponential moving average with a span of 10 on the 'Close' column in DataFrame `df_market_activity`, storing to `ema_market_activity`.\n",
    "@check_pandas_115\n",
    "def pandas_115(df_market_activity):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"ema_market_activity\": ema_market_activity}\n",
    "\n",
    "\n",
    "pandas_115()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame `df_temperature_readings` for two sensors over the year using monthly datetime index, with lineaerly increasing temperature values from 20 to 30 for Sensor1 and 15 to 25 for Sensor2.\n",
    "@check_pandas_116\n",
    "def pandas_116():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"df_temperature_readings\": df_temperature_readings}\n",
    "\n",
    "\n",
    "pandas_116()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_sales_tiers` to add a 'SalesTier' column assigned by binning the 'Sales' column into 'Low', 'Medium', and 'High' categories based on [0, 5000, 10000, 15000] bins, storing as `tiered_sales`.\n",
    "@check_pandas_117\n",
    "def pandas_117(df_sales_tiers):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"tiered_sales\": tiered_sales}\n",
    "\n",
    "\n",
    "pandas_117()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Extract month at index of DataFrame `df_time_based_events`, storing them as a new column 'EventMonth' in the DataFrame.\n",
    "@check_pandas_118\n",
    "def pandas_118(df_time_based_events):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    df_time_based_events[\"EventMonth\"] = df_time_based_events.index.month\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"df_time_based_events\": df_time_based_events}\n",
    "\n",
    "\n",
    "pandas_118()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Given a DataFrame `df_tennis_matches`, select rows using .loc where 'MatchesPlayed' > 20 and store them as `consistent_players`.\n",
    "@check_pandas_119\n",
    "def pandas_119(df_tennis_matches):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    consistent_players = df_tennis_matches.loc[df_tennis_matches[\"MatchesPlayed\"] > 20]\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"consistent_players\": consistent_players}\n",
    "\n",
    "\n",
    "pandas_119()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Utilize .iloc on DataFrame `df_daily_results` to select rows by integer location, focusing on every third row, and storing result as `every_third_result`.\n",
    "@check_pandas_120\n",
    "def pandas_120(df_daily_results):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    every_third_result = df_daily_results.iloc[::3]\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"every_third_result\": every_third_result}\n",
    "\n",
    "\n",
    "pandas_120()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# From DataFrame `df_survey_responses`, combine 'Question' and 'Answer' columns into a single 'Response' column, storing the result as a Series `consolidated_responses` in the format 'Question: Answer'.\n",
    "@check_pandas_121\n",
    "def pandas_121(df_survey_responses):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    consolidated_responses = (\n",
    "        df_survey_responses[\"Question\"] + \": \" + df_survey_responses[\"Answer\"]\n",
    "    )\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"consolidated_responses\": consolidated_responses}\n",
    "\n",
    "\n",
    "pandas_121()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_server_logs` to group by 'ServerID' and calculate the sum and max of 'ResponseTime', storing result as `server_response_summary`.\n",
    "@check_pandas_122\n",
    "def pandas_122(df_server_logs):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    server_response_summary = df_server_logs.groupby(\"ServerID\")[\"ResponseTime\"].agg(\n",
    "        [\"sum\", \"max\"]\n",
    "    )\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"server_response_summary\": server_response_summary}\n",
    "\n",
    "\n",
    "pandas_122()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Modify DataFrame `df_machine_operating` by adding column 'Downtime' calculated from 'EndTime' minus 'StartTime', storing as `operations_with_downtime`.\n",
    "@check_pandas_123\n",
    "def pandas_123(df_machine_operating):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    df_machine_operating[\"Downtime\"] = (\n",
    "        df_machine_operating[\"EndTime\"] - df_machine_operating[\"StartTime\"]\n",
    "    )\n",
    "    operations_with_downtime = df_machine_operating\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"operations_with_downtime\": operations_with_downtime}\n",
    "\n",
    "\n",
    "pandas_123()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows from DataFrame `df_patient_visits`, considering only 'PatientID' and 'VisitDate', saving unique rows as `unique_patient_visits`.\n",
    "@check_pandas_124\n",
    "def pandas_124(df_patient_visits):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    unique_patient_visits = df_patient_visits.drop_duplicates(\n",
    "        subset=[\"PatientID\", \"VisitDate\"]\n",
    "    )\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"unique_patient_visits\": unique_patient_visits}\n",
    "\n",
    "\n",
    "pandas_124()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Optimize data processing speed in DataFrame `df_satellite_data` by converting all text-based columns to category type, storing efficient version as `satellite_optimized`.\n",
    "@check_pandas_125\n",
    "def pandas_125(df_satellite_data):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    text_columns = df_satellite_data.select_dtypes(include=[\"object\"]).columns\n",
    "    df_satellite_data[text_columns] = df_satellite_data[text_columns].apply(\n",
    "        lambda x: x.astype(\"category\")\n",
    "    )\n",
    "\n",
    "    satellite_optimized = df_satellite_data\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"satellite_optimized\": satellite_optimized}\n",
    "\n",
    "\n",
    "pandas_125()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Use vectorized operations on DataFrame `df_temperature_logs` to convert 'TemperatureC' to Fahrenheit, storing the result in `temperature_fahrenheit`.\n",
    "@check_pandas_126\n",
    "def pandas_126(df_temperature_logs):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"temperature_fahrenheit\": temperature_fahrenheit}\n",
    "\n",
    "\n",
    "pandas_126()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Group DataFrame `df_streaming_data` by 'UserID' and apply a lambda function to compute total view time, storing the result as `total_view_time`.\n",
    "@check_pandas_127\n",
    "def pandas_127(df_streaming_data):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    total_view_time = df_streaming_data.groupby(\"UserID\")[\"ViewTime\"].apply(\n",
    "        lambda x: x.sum()\n",
    "    )\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"total_view_time\": total_view_time}\n",
    "\n",
    "\n",
    "pandas_127()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_sales_analytics` to implement cohort analysis, calculating first purchase date and cohort index, storing result in `sales_cohorts`.\n",
    "@check_pandas_128\n",
    "def pandas_128(df_sales_analytics):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"sales_cohorts\": sales_cohorts}\n",
    "\n",
    "\n",
    "pandas_128()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# In DataFrame `df_web_traffic`, apply conversion to 'Date' column from string to datetime, saving the updated DataFrame as `web_traffic_dates`.\n",
    "@check_pandas_129\n",
    "def pandas_129(df_web_traffic):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    df_web_traffic[\"Date\"] = pd.to_datetime(df_web_traffic[\"Date\"])\n",
    "    web_traffic_dates = df_web_traffic\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"web_traffic_dates\": web_traffic_dates}\n",
    "\n",
    "\n",
    "pandas_129()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame `df_energy_savings` with datetime index representing bi-weekly dates over one year, filled with repetitive 5% and 10% energy savings, stored in 'SavingsPercent'.\n",
    "@check_pandas_130\n",
    "def pandas_130():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\\\n",
    "    return {\"df_energy_savings\": df_energy_savings}\n",
    "\n",
    "\n",
    "pandas_130()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# With DataFrame `df_vehicle_data`, apply method chaining to filter 'Type' as 'SUV' and sort by 'RecallDate', saving sorted SUVs as `sorted_suvs`.\n",
    "@check_pandas_131\n",
    "def pandas_131(df_vehicle_data):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    sorted_suvs = df_vehicle_data[df_vehicle_data[\"Type\"] == \"SUV\"].sort_values(\n",
    "        \"RecallDate\"\n",
    "    )\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"sorted_suvs\": sorted_suvs}\n",
    "\n",
    "\n",
    "pandas_131()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Extract 'year' from 'DateAdmitted' in DataFrame `df_patient_admissions` using datetime operations, storing extracted years in `admission_years`.\n",
    "@check_pandas_132\n",
    "def pandas_132(df_patient_admissions):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    admission_years = df_patient_admissions[\"DateAdmitted\"].dt.year\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"admission_years\": admission_years}\n",
    "\n",
    "\n",
    "pandas_132()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Process DataFrame `df_cost_analysis` by converting 'Amount' to USD using 'Currency' which contains the type like ['EUR', 'GBP'] conversion rates being EUR: 1.12 and GBP: 1.30, storing result as `cost_analysis_usd` with column 'Amount' in 'Currency' and 'AmountUSD' in USD.\n",
    "@check_pandas_133\n",
    "def pandas_133(df_cost_analysis):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"cost_analysis_usd\": cost_analysis_usd}\n",
    "\n",
    "\n",
    "pandas_133()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# In DataFrame `df_logistics_data`, use rolling window of 30 days to calculate moving average inventory level, storing as `thirty_day_moving_inventory`.\n",
    "@check_pandas_134\n",
    "def pandas_134(df_logistics_data):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"thirty_day_moving_inventory\": thirty_day_moving_inventory}\n",
    "\n",
    "\n",
    "pandas_134()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# From DataFrame `df_sports_results`, extract top three teams based on 'Scores', sorting first, saving top teams as `top_teams`.\n",
    "@check_pandas_135\n",
    "def pandas_135(df_sports_results):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    top_teams = df_sports_results.nlargest(3, \"Scores\")\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"top_teams\": top_teams}\n",
    "\n",
    "\n",
    "pandas_135()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_network_activity` statistics to calculate z-scores for 'Bandwidth', storing in column 'ZscoreBandwidth' as `network_with_zscore`.\n",
    "@check_pandas_136\n",
    "def pandas_136(df_network_activity):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    df_network_activity[\"ZscoreBandwidth\"] = (\n",
    "        df_network_activity[\"Bandwidth\"] - df_network_activity[\"Bandwidth\"].mean()\n",
    "    ) / df_network_activity[\"Bandwidth\"].std()\n",
    "    network_with_zscore = df_network_activity\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"network_with_zscore\": network_with_zscore}\n",
    "\n",
    "\n",
    "pandas_136()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Perform inplace boolean update of `df_market_responses` setting all 'ResponseTime' > 300 to 300, saving updated DataFrame.\n",
    "@check_pandas_137\n",
    "def pandas_137(df_market_responses):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    df_market_responses.loc[\n",
    "        df_market_responses[\"ResponseTime\"] > 300, \"ResponseTime\"\n",
    "    ] = 300\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"df_market_responses\": df_market_responses}\n",
    "\n",
    "\n",
    "pandas_137()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Analyze DataFrame `df_social_behaviors` applying transform with a custom function to 'EngagementRate' to normalize within each 'Group' by z-score, storing as 'NormalizedEngagementRate'.\n",
    "@check_pandas_138\n",
    "def pandas_138(df_social_behaviors):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    df_social_behaviors[\"NormalizedEngagementRate\"] = df_social_behaviors.groupby(\n",
    "        \"Group\"\n",
    "    )[\"EngagementRate\"].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"df_social_behaviors\": df_social_behaviors}\n",
    "\n",
    "\n",
    "pandas_138()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use DataFrame `df_product_launch` to derive 'ResponseRate' from 'Inquiries' divided by 'Sales', multiplied by 100, storing as `launch_responses`.\n",
    "@check_pandas_139\n",
    "def pandas_139(df_product_launch):\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    df_product_launch[\"ResponseRate\"] = (\n",
    "        df_product_launch[\"Inquiries\"] / df_product_launch[\"Sales\"]\n",
    "    ) * 100\n",
    "\n",
    "    launch_responses = df_product_launch\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"launch_responses\": launch_responses}\n",
    "\n",
    "\n",
    "pandas_139()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `create_series_from_dict` that takes a dictionary `input_dict` as an argument, and returns a pandas Series with the dictionary keys as the Series index.\n",
    "@check_pandas_140\n",
    "def pandas_3():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"create_series_from_dict\": create_series_from_dict}\n",
    "\n",
    "\n",
    "pandas_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `filter_series_positive` that takes a pandas Series `data_series` and returns a new Series containing only the elements where the value is positive.\n",
    "@check_pandas_141\n",
    "def pandas_4():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"filter_series_positive\": filter_series_positive}\n",
    "\n",
    "\n",
    "pandas_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `rename_dataframe_columns` that accepts a DataFrame `df` and a dictionary `column_mapping`, and returns the DataFrame with renamed columns according to the mapping.\n",
    "@check_pandas_142\n",
    "def pandas_142():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"rename_dataframe_columns\": rename_dataframe_columns}\n",
    "\n",
    "\n",
    "pandas_142()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `drop_nan_rows` that takes a DataFrame `input_df` and returns a new DataFrame with all rows containing any NaN values removed.\n",
    "@check_pandas_143\n",
    "def pandas_143():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"drop_nan_rows\": drop_nan_rows}\n",
    "\n",
    "\n",
    "pandas_143()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Construct a function `fill_missing_with_mean` which takes a DataFrame `df` and fills missing values in each numeric column with the mean of that column, returning the modified DataFrame.\n",
    "@check_pandas_144\n",
    "def pandas_144():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def fill_missing_with_mean(df):\n",
    "        return df.fillna(df.mean())\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"fill_missing_with_mean\": fill_missing_with_mean}\n",
    "\n",
    "\n",
    "pandas_144()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `calculate_group_means` that takes a DataFrame `df` and a column name `group_col`, grouping by `group_col`, then returning the mean of each group as a Series.\n",
    "@check_pandas_145\n",
    "def pandas_145():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def calculate_group_means(df, group_col):\n",
    "        return df.groupby(group_col).mean()\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_group_means\": calculate_group_means}\n",
    "\n",
    "\n",
    "pandas_145()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Design a function `subset_dataframe_label` that accepts a DataFrame `df`, a list `rows` of row labels, and returns a subset DataFrame containing only those rows.\n",
    "@check_pandas_146\n",
    "def pandas_146():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def subset_dataframe_label(df, rows):\n",
    "        return df.loc[rows]\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"subset_dataframe_label\": subset_dataframe_label}\n",
    "\n",
    "\n",
    "pandas_146()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `merge_dataframes_on_key` that takes two DataFrames `df1`, `df2`, and a string `key`, merging them on the shared key column and returning the merged DataFrame.\n",
    "@check_pandas_147\n",
    "def pandas_147():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def merge_dataframes_on_key(df1, df2, key):\n",
    "        return pd.merge(df1, df2, on=key)\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"merge_dataframes_on_key\": merge_dataframes_on_key}\n",
    "\n",
    "\n",
    "pandas_147()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `aggregate_sales_by_region` which accepts a DataFrame `sales_df` that includes columns 'Region' and 'Sales', and returns a DataFrame with the total sales per region.\n",
    "@check_pandas_148\n",
    "def pandas_148():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"aggregate_sales_by_region\": aggregate_sales_by_region}\n",
    "\n",
    "\n",
    "pandas_148()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `pivot_table_for_analysis` that takes a DataFrame `df` and strings `index`, `columns`, `values`, and returns a pivot table using those specifications.\n",
    "@check_pandas_149\n",
    "def pandas_149():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def pivot_table_for_analysis(df, index, columns, values):\n",
    "        return df.pivot_table(index=index, columns=columns, values=values)\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"pivot_table_for_analysis\": pivot_table_for_analysis}\n",
    "\n",
    "\n",
    "pandas_149()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `calculate_rolling_average` that accepts a DataFrame `df` and an integer `window` to compute the rolling average of a numeric column `column_name`, returning the updated series.\n",
    "@check_pandas_150\n",
    "def pandas_150():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def calculate_rolling_average(df, column_name, window):\n",
    "        return df[column_name].rolling(window=window).mean()\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_rolling_average\": calculate_rolling_average}\n",
    "\n",
    "\n",
    "pandas_150()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Construct a function `resample_time_series` which takes a time-indexed DataFrame `time_df` and a frequency string `freq`, resampling the DataFrame to the new frequency and summing, returning the result.\n",
    "@check_pandas_151\n",
    "def pandas_151():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def resample_time_series(time_df, freq):\n",
    "        return time_df.resample(freq).sum()\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"resample_time_series\": resample_time_series}\n",
    "\n",
    "\n",
    "pandas_151()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `expand_string_columns` that takes a DataFrame `df` and a list of columns `string_columns`, expanding each string column to lowercase, and returns the modified DataFrame.\n",
    "@check_pandas_152\n",
    "def pandas_152():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def expand_string_columns(df, string_columns):\n",
    "        for col in string_columns:\n",
    "            df[col] = df[col].str.lower()\n",
    "        return df\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"expand_string_columns\": expand_string_columns}\n",
    "\n",
    "\n",
    "pandas_152()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Design a function `convert_to_datetime_index` that accepts a DataFrame `df` and a column name `date_col`, converting it to a DateTimeIndex, and returning the updated DataFrame.\n",
    "@check_pandas_153\n",
    "def pandas_153():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def convert_to_datetime_index(df, date_col):\n",
    "        df[date_col] = pd.to_datetime(df[date_col])\n",
    "        df.set_index(date_col, inplace=True)\n",
    "        return df\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"convert_to_datetime_index\": convert_to_datetime_index}\n",
    "\n",
    "\n",
    "pandas_153()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `identify_and_remove_outliers` that identifies outliers in a Series `data_series` using a specified `threshold` by removing the values outside of the `threshodl` multiplied by the standard deviation from the mean.\n",
    "@check_pandas_154\n",
    "def pandas_154():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def identify_and_remove_outliers(data_series, threshold):\n",
    "        mean = data_series.mean()\n",
    "        std_dev = data_series.std()\n",
    "        return data_series[\n",
    "            (data_series >= mean - threshold * std_dev)\n",
    "            & (data_series <= mean + threshold * std_dev)\n",
    "        ]\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"identify_and_remove_outliers\": identify_and_remove_outliers}\n",
    "\n",
    "\n",
    "pandas_154()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `calculate_percentage_change` which computes the percentage change over time for a Series `time_series` and returns the updated Series with NaN for the first entry.\n",
    "@check_pandas_155\n",
    "def pandas_155():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_percentage_change\": calculate_percentage_change}\n",
    "\n",
    "\n",
    "pandas_155()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `categorize_based_on_values` which takes a DataFrame `df`, a column `categorical_col`, and returns a DataFrame with additional column 'Category' based on ranges in `categorical_col` with labels ['Low', 'Medium', 'High'] and bins [0, 100, 200, 300].\n",
    "@check_pandas_156\n",
    "def pandas_156():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"categorize_based_on_values\": categorize_based_on_values}\n",
    "\n",
    "\n",
    "pandas_156()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `shift_dataframe_rows` that takes a DataFrame `df` and an integer `periods`, shifting all rows by the specified number of periods and returning the DataFrame.\n",
    "@check_pandas_157\n",
    "def pandas_157():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def shift_dataframe_rows(df, periods):\n",
    "        return df.shift(periods)\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"shift_dataframe_rows\": shift_dataframe_rows}\n",
    "\n",
    "\n",
    "pandas_157()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `aggregate_and_flatten_grouped` that takes a grouped DataFrame `group_df` and returns a flattened DataFrame with 'sum' and 'count' aggregation for each group and reseted index.\n",
    "@check_pandas_158\n",
    "def pandas_158():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def aggregate_and_flatten_grouped(group_df):\n",
    "        return group_df.agg([\"sum\", \"count\"]).reset_index()\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"aggregate_and_flatten_grouped\": aggregate_and_flatten_grouped}\n",
    "\n",
    "\n",
    "pandas_158()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Construct a function named `remove_duplicates_by_columns` that takes a DataFrame `df` and a list `subset_columns`, and removes duplicate rows based on these columns, returning the resulting DataFrame.\n",
    "@check_pandas_159\n",
    "def pandas_159():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def remove_duplicates_by_columns(df, subset_columns):\n",
    "        return df.drop_duplicates(subset=subset_columns)\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"remove_duplicates_by_columns\": remove_duplicates_by_columns}\n",
    "\n",
    "\n",
    "pandas_159()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Design a function `calculate_memory_usage` that takes a DataFrame `df` and returns the total memory usage in MB, both with and without optimizations for all columns possible.\n",
    "@check_pandas_160\n",
    "def pandas_160():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_memory_usage\": calculate_memory_usage}\n",
    "\n",
    "\n",
    "pandas_160()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `map_values_with_dict` which accepts a DataFrame `df`, a column `target_col`, and a dictionary `value_map`, returning the updated DataFrame after mapping.\n",
    "@check_pandas_161\n",
    "def pandas_161():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def map_values_with_dict(df, target_col, value_map):\n",
    "        df[target_col] = df[target_col].map(value_map)\n",
    "        return df\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"map_values_with_dict\": map_values_with_dict}\n",
    "\n",
    "\n",
    "pandas_161()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `select_top_n_rows_based_on_column` that takes a DataFrame `df`, a column `target_col`, and an integer `n`, and returns the top `n` rows sorted by `target_col`.\n",
    "@check_pandas_162\n",
    "def pandas_162():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def select_top_n_rows_based_on_column(df, target_col, n):\n",
    "        return df.nlargest(n, target_col)\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"select_top_n_rows_based_on_column\": select_top_n_rows_based_on_column}\n",
    "\n",
    "\n",
    "pandas_162()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `replace_substrings_in_column` that takes a DataFrame `df`, a column `text_col`, a string `old`, and a string `new`, replacing all occurrences of `old` with `new` in `text_col`.\n",
    "@check_pandas_163\n",
    "def pandas_163():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def replace_substrings_in_column(df, text_col, old, new):\n",
    "        df[text_col] = df[text_col].str.replace(old, new)\n",
    "        return df\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"replace_substrings_in_column\": replace_substrings_in_column}\n",
    "\n",
    "\n",
    "pandas_163()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `apply_discretization_binner` which bins Series `data_series` into a specified number of discrete intervals `n_bins` and returns the binned Series.\n",
    "@check_pandas_164\n",
    "def pandas_164():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def apply_discretization_binner(data_series, n_bins):\n",
    "        return pd.cut(data_series, bins=n_bins)\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"apply_discretization_binner\": apply_discretization_binner}\n",
    "\n",
    "\n",
    "pandas_164()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `generate_descriptive_statistics` that takes a DataFrame `df` and returns a DataFrame with descriptive statistics such as mean, median, and standard deviation for all numeric columns.\n",
    "@check_pandas_165\n",
    "def pandas_165():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"generate_descriptive_statistics\": generate_descriptive_statistics}\n",
    "\n",
    "\n",
    "pandas_165()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `convert_column_dtype` that accepts a DataFrame `df`, a column name `col`, and a data type `new_type`, and returns the DataFrame with `col` converted to `new_type`.\n",
    "@check_pandas_166\n",
    "def pandas_166():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    def convert_column_dtype(df, col, new_type):\n",
    "        df[col] = df[col].astype(new_type)\n",
    "        return df\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"convert_column_dtype\": convert_column_dtype}\n",
    "\n",
    "\n",
    "pandas_166()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `sort_dataframe_by_multiple_columns` taking DataFrame `df` and a list `columns_list` to sort the DataFrame by these columns, returning the sorted DataFrame.\n",
    "@check_pandas_167\n",
    "def pandas_167():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    def sort_dataframe_by_multiple_columns(df, columns_list):\n",
    "        return df.sort_values(by=columns_list)\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"sort_dataframe_by_multiple_columns\": sort_dataframe_by_multiple_columns}\n",
    "\n",
    "\n",
    "pandas_167()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `create_time_based_features` which accepts a DataFrame `time_df` with a 'Timestamp' column and returns the DataFrame with new columns for hour, day, and month.\n",
    "@check_pandas_168\n",
    "def pandas_168():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    def create_time_based_features(time_df):\n",
    "        time_df[\"Hour\"] = time_df[\"Timestamp\"].dt.hour\n",
    "        time_df[\"Day\"] = time_df[\"Timestamp\"].dt.day\n",
    "        time_df[\"Month\"] = time_df[\"Timestamp\"].dt.month\n",
    "        return time_df\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"create_time_based_features\": create_time_based_features}\n",
    "\n",
    "\n",
    "pandas_168()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `analyze_sales_data` that takes a DataFrame `sales_df` with columns 'Date', 'Region', and 'Sales'. The function should: Convert 'Date' to a DateTime object; Filter out any rows where 'Sales' is negative; Group by 'Region' to calculate the total and average sales; Return a DataFrame with columns 'Region', 'TotalSales', 'AverageSales';\n",
    "@check_pandas_169\n",
    "def pandas_169():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    def analyze_sales_data(sales_df):\n",
    "        sales_df[\"Date\"] = pd.to_datetime(sales_df[\"Date\"])\n",
    "        sales_df = sales_df[sales_df[\"Sales\"] >= 0]\n",
    "        result = (\n",
    "            sales_df.groupby(\"Region\")\n",
    "            .agg(TotalSales=(\"Sales\", \"sum\"), AverageSales=(\"Sales\", \"mean\"))\n",
    "            .reset_index()\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"analyze_sales_data\": analyze_sales_data}\n",
    "\n",
    "\n",
    "pandas_169()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `clean_and_merge_datasets` that takes two DataFrames `df_left` and `df_right`, and: Fills NA values in `df_left` with 0; Drops any duplicate rows in `df_right`; Merges the cleaned DataFrames on a common column 'Key', using an outer join; Returns the merged DataFrame sorted by 'Key';\n",
    "@check_pandas_170\n",
    "def pandas_170():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    def clean_and_merge_datasets(df_left, df_right):\n",
    "        df_left.fillna(0, inplace=True)\n",
    "        df_right.drop_duplicates(inplace=True)\n",
    "        merged_df = pd.merge(df_left, df_right, on=\"Key\", how=\"outer\")\n",
    "        return merged_df.sort_values(by=\"Key\")\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"clean_and_merge_datasets\": clean_and_merge_datasets}\n",
    "\n",
    "\n",
    "pandas_170()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `process_sensor_data_batch` that receives a DataFrame `sensor_df` containing 'SensorID', 'ReadingValue', 'Timestamp'. Convert 'Timestamp' to datetime format; Ensure all 'ReadingValue' entries are non-negative; Calculate the mean and standard deviation of 'ReadingValue' for each 'SensorID'; Return a DataFrame with 'SensorID', 'MeanReading', 'StdDevReading';\n",
    "@check_pandas_171\n",
    "def pandas_171():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    def process_sensor_data_batch(sensor_df):\n",
    "        sensor_df[\"Timestamp\"] = pd.to_datetime(sensor_df[\"Timestamp\"])\n",
    "        sensor_df = sensor_df[sensor_df[\"ReadingValue\"] >= 0]\n",
    "        sensor_stats = (\n",
    "            sensor_df.groupby(\"SensorID\")[\"ReadingValue\"]\n",
    "            .agg(MeanReading=\"mean\", StdDevReading=\"std\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        return sensor_stats\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"process_sensor_data_batch\": process_sensor_data_batch}\n",
    "\n",
    "\n",
    "pandas_171()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great job! Exercise completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Construct a function `analyze_customer_behaviors` to handle a DataFrame `customer_df` with columns 'CustomerID', 'PurchaseAmount', 'VisitTimestamp'. Convert 'VisitTimestamp' to a DateTimeIndex; Filter to include only purchases greater than a specified `min_purchase`; Group by 'CustomerID' to determine the total and count of purchases; Return a DataFrame with 'CustomerID', 'TotalPurchases', 'NumberVisits', and attach the most recent visit date;\n",
    "@check_pandas_172\n",
    "def pandas_172():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "    def analyze_customer_behaviors(customer_df, min_purchase):\n",
    "        customer_df[\"VisitTimestamp\"] = pd.to_datetime(customer_df[\"VisitTimestamp\"])\n",
    "        customer_df = customer_df[customer_df[\"PurchaseAmount\"] > min_purchase]\n",
    "        customer_behavior = (\n",
    "            customer_df.groupby(\"CustomerID\")\n",
    "            .agg(\n",
    "                TotalPurchases=(\"PurchaseAmount\", \"sum\"),\n",
    "                NumberVisits=(\"PurchaseAmount\", \"count\"),\n",
    "                MostRecentVisit=(\"VisitTimestamp\", \"max\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "        return customer_behavior\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"analyze_customer_behaviors\": analyze_customer_behaviors}\n",
    "\n",
    "\n",
    "pandas_172()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `transform_financial_data` that processes a DataFrame `financial_df` including columns 'AccountID', 'TransactionDate', 'Amount'. Parse 'TransactionDate' into datetime and set as index; Filter 'Amount' to exclude NaN and zero values; Extract month and year from 'TransactionDate' into new columns `Month`, `Year`; Group by 'AccountID' and 'Year' to summarize monthly 'Amount' into sum and mean, returning a structured DataFrame;\n",
    "@check_pandas_173\n",
    "def pandas_173():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"transform_financial_data\": transform_financial_data}\n",
    "\n",
    "\n",
    "pandas_173()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `aggregate_weather_data` for a DataFrame `weather_df` with fields 'StationID', 'Temp', 'Humidity', 'ObservationTime'. Convert 'ObservationTime' to a DateTimeIndex; Filter to retain records with positive 'Temp' and 'Humidity'; Resample to daily frequency, taking the mean for each day; Return a DataFrame grouped by 'StationID' with columns for daily average 'Temp' and 'Humidity';\n",
    "@check_pandas_174\n",
    "def pandas_174():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"aggregate_weather_data\": aggregate_weather_data}\n",
    "\n",
    "\n",
    "pandas_174()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Design a function `standardize_student_record` to clean a DataFrame `student_df` featuring 'Name', 'Score', 'SubmissionDate'. Standardize 'Name' to have a capitalized first letter; Address missing 'Score' values by assigning the median score; Standardize 'SubmissionDate' to a consistent format and compute 'DaysSinceSubmission'; Return a DataFrame with standardized names, computed days since submission, and filled scores;\n",
    "@check_pandas_175\n",
    "def pandas_175():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"standardize_student_record\": standardize_student_record}\n",
    "\n",
    "\n",
    "pandas_175()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `construct_inventory_report` that takes a DataFrame `inventory_df` with 'ItemID', 'Quantity', 'RestockDate'. Parse 'RestockDate' to ensure it's in datetime format; Identify items needing restock by checking 'Quantity' against the `threshold`; Provide a summary count of items needing restock by month; Return a detailed DataFrame with 'ItemID', 'Quantity', 'DaysUntilRestock', plus a monthly summary DataFrame;\n",
    "@check_pandas_176\n",
    "def pandas_176():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"construct_inventory_report\": construct_inventory_report}\n",
    "\n",
    "\n",
    "pandas_176()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iulia\\AppData\\Local\\Temp\\ipykernel_23708\\1824062139.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  forecast_df['ProjectedSales'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\iulia\\AppData\\Local\\Temp\\ipykernel_23708\\1824062139.py:10: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  forecast_df['ProjectedSales'].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `optimize_sales_forecast` that works on DataFrame `forecast_df` with columns 'Product', 'ProjectedSales', 'ForecastDate'. Convert 'ForecastDate' to DateTime format; Apply forward fill to handle missing 'ProjectedSales' values; Conduct a rolling window analysis to compute the 3-month moving average of sales; Return an extended DataFrame with moving averages along with original columns;\n",
    "@check_pandas_177\n",
    "def pandas_177():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"optimize_sales_forecast\": optimize_sales_forecast}\n",
    "\n",
    "\n",
    "pandas_177()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `summarize_employee_performance` that processes DataFrame `performance_df` with 'EmployeeID', 'Score', 'ReviewDate'. Ensure 'ReviewDate' is converted into a datetime object; Replace missing 'Score' with the lowest non-zero score; Group by 'EmployeeID' to compute total and average score; Generate a DataFrame highlighting top performers with scores above a specified percentile score; Audit history, including evaluation of performance improvement over time;\n",
    "@check_pandas_178\n",
    "def pandas_178():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"summarize_employee_performance\": summarize_employee_performance}\n",
    "\n",
    "\n",
    "pandas_178()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `double_series_values` that takes a Series `input_series` and returns a Series with all values doubled.\n",
    "@check_pandas_179\n",
    "def pandas_179():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"double_series_values\": double_series_values}\n",
    "\n",
    "\n",
    "pandas_179()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `replace_zeros_with_mean` that takes a Series `data_series` and replaces all 0 values with the mean of the Series, returning the modified Series.\n",
    "@check_pandas_180\n",
    "def pandas_180():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"replace_zeros_with_mean\": replace_zeros_with_mean}\n",
    "\n",
    "\n",
    "pandas_180()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Design a function `standardize_column_names` that accepts a DataFrame `df` and returns it with all column names set to lowercase.\n",
    "@check_pandas_181\n",
    "def pandas_181():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"standardize_column_names\": standardize_column_names}\n",
    "\n",
    "\n",
    "pandas_181()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `drop_duplicate_rows` that receives a DataFrame `df` and returns it with duplicate rows removed.\n",
    "@check_pandas_182\n",
    "def pandas_182():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"drop_duplicate_rows\": drop_duplicate_rows}\n",
    "\n",
    "\n",
    "pandas_182()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `calculate_column_sums` that takes a DataFrame `df` and returns a Series containing the sum of each column.\n",
    "@check_pandas_183\n",
    "def pandas_183():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_column_sums\": calculate_column_sums}\n",
    "\n",
    "\n",
    "pandas_183()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `extract_date_parts` that takes a Series `dates` of datetime objects and returns a DataFrame with columns 'Year', 'Month', and 'Day'.\n",
    "@check_pandas_184\n",
    "def pandas_184():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"extract_date_parts\": extract_date_parts}\n",
    "\n",
    "\n",
    "pandas_184()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `concat_strings_in_column` that, given a DataFrame `df` and a column `text_col`, concatenates all strings in that column with a space in between, returning the result string.\n",
    "@check_pandas_185\n",
    "def pandas_185():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"concat_strings_in_column\": concat_strings_in_column}\n",
    "\n",
    "\n",
    "pandas_185()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `sort_by_index_descending` that accepts a DataFrame `df` and returns it sorted by its index in descending order.\n",
    "@check_pandas_186\n",
    "def pandas_186():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"sort_by_index_descending\": sort_by_index_descending}\n",
    "\n",
    "\n",
    "pandas_186()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `filter_by_threshold` to take a DataFrame `df` and a column name `col`, returning a DataFrame including only rows where `col` is above a given threshold.\n",
    "@check_pandas_187\n",
    "def pandas_187():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"filter_by_threshold\": filter_by_threshold}\n",
    "\n",
    "\n",
    "pandas_187()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `get_unique_values` that takes a DataFrame `df` and a column `col`, returning a sorted array of unique values in the specified column.\n",
    "@check_pandas_188\n",
    "def pandas_188():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"get_unique_values\": get_unique_values}\n",
    "\n",
    "\n",
    "pandas_188()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `append_row_to_dataframe` that takes a DataFrame `df` and a dictionary `row_dict`, appending the dictionary as a new row, and returning the updated DataFrame.\n",
    "@check_pandas_189\n",
    "def pandas_189():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"append_row_to_dataframe\": append_row_to_dataframe}\n",
    "\n",
    "\n",
    "pandas_189()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Construct a function `reset_index_and_name` that takes a DataFrame `df` and returns it with its index reset and the name of the index set to 'NewIndex'.\n",
    "@check_pandas_190\n",
    "def pandas_190():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"reset_index_and_name\": reset_index_and_name}\n",
    "\n",
    "\n",
    "pandas_190()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `swap_dataframe_columns` that accepts a DataFrame `df` and two column names `col1` and `col2`, swapping the values of these columns.\n",
    "@check_pandas_191\n",
    "def pandas_191():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"swap_dataframe_columns\": swap_dataframe_columns}\n",
    "\n",
    "\n",
    "pandas_191()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `rename_index_label` which receives a DataFrame `df`, renames its first index label to 'FirstRow', and returns the DataFrame.\n",
    "@check_pandas_192\n",
    "def pandas_192():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"rename_index_label\": rename_index_label}\n",
    "\n",
    "\n",
    "pandas_192()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `calculate_frequency_table` that, given a DataFrame `df` and a column `cat_col`, returns a DataFrame with a frequency count of each category with columns Category and count.\n",
    "@check_pandas_193\n",
    "def pandas_193():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_frequency_table\": calculate_frequency_table}\n",
    "\n",
    "\n",
    "pandas_193()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Implement a function `remove_negative_entries` that takes a Series `numeric_series` and returns a Series with all negative entries removed.\n",
    "@check_pandas_194\n",
    "def pandas_194():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"remove_negative_entries\": remove_negative_entries}\n",
    "\n",
    "\n",
    "pandas_194()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `sort_column_values` that takes a DataFrame `df` and column name `col`, returning `df` sorted by `col` values in ascending order.\n",
    "@check_pandas_195\n",
    "def pandas_195():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"sort_column_values\": sort_column_values}\n",
    "\n",
    "\n",
    "pandas_195()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Design a function `drop_columns_by_name` that accepts a DataFrame `df` and a list of column names `drop_cols`, removing these columns and returning the modified DataFrame.\n",
    "@check_pandas_196\n",
    "def pandas_196():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"drop_columns_by_name\": drop_columns_by_name}\n",
    "\n",
    "\n",
    "pandas_196()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Develop a function `strip_whitespace` that takes a DataFrame `df` and trims leading and trailing whitespace from all string entries.\n",
    "@check_pandas_197\n",
    "def pandas_197():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"strip_whitespace\": strip_whitespace}\n",
    "\n",
    "\n",
    "pandas_197()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Create a function `duplicate_last_column` that receives a DataFrame `df` and duplicates its last column, appending the duplicate to the right of the DataFrame named as the original column with '_copy' appended.\n",
    "@check_pandas_198\n",
    "def pandas_198():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"duplicate_last_column\": duplicate_last_column}\n",
    "\n",
    "\n",
    "pandas_198()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Write a function `filter_top_n_rows_by_column` that takes a DataFrame `df`, a column `col`, and an integer `n`, returning the top n rows sorted by values in `col`.\n",
    "@check_pandas_199\n",
    "def pandas_199():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"filter_top_n_rows_by_column\": filter_top_n_rows_by_column}\n",
    "\n",
    "\n",
    "pandas_199()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ The implementation is incorrect or the exercise was not implemented.\n"
     ]
    }
   ],
   "source": [
    "# Define a function `calculate_range_of_numeric_series` that takes a Series `numeric_series` and returns the range (max - min) of its values.\n",
    "@check_pandas_200\n",
    "def pandas_200():\n",
    "    # This line is mandatory and should not be removed.\n",
    "    ex_stat_init = True\n",
    "\n",
    "    # BELOW GOES YOUR CODE\n",
    "\n",
    "    # ABOVE GOES YOUR CODE\n",
    "    return {\"calculate_range_of_numeric_series\": calculate_range_of_numeric_series}\n",
    "\n",
    "\n",
    "pandas_200()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
